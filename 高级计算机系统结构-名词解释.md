# 名词解释

**高性能计算**：HPC（High Performance Compute）泛指量大、快速、高效的运算

**处理机**：Processor 不能构成一个完整的计算机。

**FLOPS**：每秒所执行的浮点数运算次数

**Flynn分类**：
- SISD（Single-Instruction Single-Data）
- SIMD（Single-Instruction Multi-Data）
- MISD（Multi-Instruction Single-Data）
- MIMD（Multi-Instruction Multi-Data）

**PVP**：并行向量处理机（Parallel Vector Processor），含有为数不多、功能强大的定制向量处理器，以及定制的高带宽纵横交叉开关和高速数据访问。

**COW**：工作站机群、机群系统（Cluster of Workstation，Cluster；Network Of Workstations，NOW），每个节点都是一个完整的计算机有着完整的操作系统，系统由多个节点组成，相对独立，每台服务器拥有自己的内存，各自的 CPU 无法直接访问其他服务器的内存。各个节点通过高性能网络相互连接，网络接口和 IO 总线松耦合链接。

**MPP**：分布存储，大规模并行处理机（Massively Parallel Processor），物理和逻辑上均是分布内存，计算能力强、规模庞大、结构复杂。采用几百到上万个基于 RISC 指令集的处理器，组成大型并行计算机系统。采用高通信带宽和低延迟的互联网络（专门设计和定制的）。属于 MIMD，程序有多个进程组成，每个进程都有其私有的地址空间，进程间采用传递消息互相作用。

**SMP**：对称多处理机（Symmetric Multiprocessor），几个计算机上汇集了一组处理器（多 CPU），各个 CPU 之间共享内存子系统以及总线结构。处理机之间无主从之分，对外有相同的访问权，都有执行操作系统核心和I/O服务程序的能力。共享存储器、统一地址空间，系统编程比较容易。
  - 对称式共享存储：任意处理器可直接访问任意内存地址，且访问延迟、带宽、几率都是等价的，系统是对称的。

**DSM**：分布式共享存储系统（Distributed Shared Memory），内存模块物理上局部于各个处理器内部，但逻辑上（用户）是共享存储的；这种结构也称为基于 Cache 目录的非一致内存访问（CC-NUMA）结构；局部与远程内存访问的延迟和带宽不一致，大约相差3-10倍。

**UMA**：统一内存访问（Uniform Memory Access），属于单地址空间共享存储器，范畴是多处理机之间的。物理存储器被所有处理机均匀共享，所有处理机对所有存储字具有相同的存取时间。例如 PVP、SMP。

**NUMA**：非统一内存访问（Non-Uniform Memory Access），属于单地址空间共享存储器，范畴是多处理机之间的。所有处理器都一样，但是每个处理器拥有自己的本地内存，访问其他内存需要通过互连网络和其他处理机通信，访问时间随存储字的位置不同而变化。例如 DSM。

**NORMA**：No-Remote Memory Access，属于多地址空间非共享存储器，范畴是多计算机之间的，是分布式存储。例如：MPP、COW。

**COMA**：Cache-Only Memory Architecture，只用高速缓存的多处理机，远程高速缓存访问则借助于分布高速缓存目录进行。

**Memory Wall**：存储器访问能力与处理部件计算能力的不平衡。

**Programming Wall**：系统规模增大到10万个以上处理器，系统结构复杂（数据共享与消息通信模式交织），为超级计算机编写高效健壮程序越来越复杂，越来越困难。

**计算机体系结构的定义**：对计算机系统而言是指那些由程序员可见的系统属性。

**芯片级并行性**：独立的控制流、分离的内部状态、没有共享的功能部件。
  - 同构多核
  - 异构多核

**性能评价的常用方法**：时钟频率（主频）、指令执行速度（经典方法，MIPS）、等效指令速度（吉普森法）、数据处理速率 PDR（Processing Data Rate）、峰值速度、核心程序

**计算机性能**：通常指机器的执行速度，是程序执行时间的倒数，另外还包括正确性、可靠性等。

**评价的性能**：仅指工作能力/性能分为峰值性能和持续性能，侧重评价持续性能。

**工作能力指标**：
  - 处理能力（单位时间内能处理的信息量）
  - 响应能力（输入任务到输出结果（系统）的时间）
  - 利用率（时间段 T 内，部件被使用时间 t 与 T 的比值）

**吞吐率**：单位时间内能处理的作业数。

**并行度**：（Degree of Parallelism，DOP），是在一定时间间隔内执行一个程序所用的处理机的数目。

**Amdahl Law**：固定规模加速比模型，问题规模不随着处理及变化而变化。固定问题规模，看用并行技术能达到的最短时间是多少。

**Gustafsun Law**：固定时间加速比性能模型

**受限于存储器的加速比模型**：在存储空间有限条件下解尽可能大的问题，这同样需要扩展工作负载，才能提供较高的加速比、较高的精度和较好的资源利用率。

**指令级并行**：指令之间可重叠执行性。

**流水线**：是实现多条指令重叠执行的技术，是加快 CPU 执行速度的关键技术。

**流水级**：Pipeline Stage，流水线由多个流水级组成，通常一条指令由 N 级流水线级完成。每个流水线级完成指令的部分任务。

**吞吐量**：单位时间内流出流水线的指令数

**机器周期**：Machine Cycle，不同流水线完成指令功能不等，所需时间有长有短，因此设计流水线的关键是合理划分指令功能，使得每一级流水级完成指令功能的时间大致相等。机器周期由最长流水级的时间决定，通常等于时钟周期。

**流水线竞争**：Pipeline Hazard，是流水线中造成下一条指令不能再指令时钟周期被执行的情况。
  - 结构竞争：硬件资源冲突引起，例如，单口存储器造成存储器访问冲突
  - 数据竞争：下一条指令要用到上一条指令的结果
  - 数据冒险
    - RAW 写后读
    - WAW 写后写
    - WAR 读后写
  - 真相关：后一条指令需要用到前一条指令的结果，或按照前述情况形成相关链。单指令内的相关性不认为是相关的。
  - 名称相关：两条指令使用同一个寄存器或者存储器，但是两条指令之间不存在数据流动
    - 反相关：后一条指令需要往前一条指令读取的寄存器或者存储器中写入时发生
    - 输出相关：两条指令对同一个寄存器或者存储器中写入时发生
  - 控制竞争：由转移指令或其他改变PC指令引起

**编译器调度**：由编译器重新安排指令执行顺序，以避免停顿周期

**延迟转移方法**：Delayed Branch，在开始处理转移指令到明确转移是否发生之间，存在一段转移延迟时间，称为转移延迟槽（Branch Delay Slot）

**循环并行性**：循环的多次迭代之间的并行性，属于指令级并行性

**程序基本块**：不包括转入和转出指令的连续代码序列

**记分牌**：是一集中控制部件，其功能是控制数据寄存器与处理部件之间的数据传送
